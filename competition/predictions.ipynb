{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1llZIukjmHhGelID8v4DR0WDtJBzhfWBh","authorship_tag":"ABX9TyNphM9Zt8r3HpZS0OtomF8v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2cU1hIYQ-Cow","executionInfo":{"status":"ok","timestamp":1739027351663,"user_tz":-60,"elapsed":2818,"user":{"displayName":"malama chali","userId":"16385961368052158169"}},"outputId":"98d92b1e-231f-4c18-c7bc-0122ae2bca50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n"]}],"source":["import pandas as pd\n","!pip install joblib\n","import joblib\n","import numpy as np\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder , StandardScaler"]},{"cell_type":"markdown","source":["#**Prepare the testing dataset for the competiton**"],"metadata":{"id":"HN3ZyQqA-iE3"}},{"cell_type":"code","source":["#load the testing set\n","test_filepath= '/content/drive/MyDrive/ML-AI projects/titanic survival prediction/Titanic_survival_prediction/dataset/test.csv'\n","df= pd.read_csv(test_filepath)\n","passId= df['PassengerId']\n","df=df.drop(['Name','Ticket','Cabin','PassengerId',],axis=1)\n","print(df.describe())\n","\n","#check for missing values\n","missing_values=df.isna().sum()\n","print(\"the number of missing values per feature is \\n\",missing_values)\n","\n","#handle the missing values\n","features_to_impute=['Age','Fare']\n","imputer=SimpleImputer(missing_values=np.nan , strategy= 'mean' )\n","df[features_to_impute]= imputer.fit_transform(df[features_to_impute])\n","missing_values=df.isna().sum()\n","print(\"the number of missing values per feature after imputation is \\n\",missing_values)\n","\n","#encoding the categorical values\n","categorical_features= df.select_dtypes(include=['object']).columns.tolist()\n","print(\"the categorical features are \",categorical_features)\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(),categorical_features)],remainder='passthrough')\n","df_encoded= ct.fit_transform(df) # nb the encoder returns an array and not a dataframe\n","\n","#get new column names\n","encoded_columns= ct.transformers_[0][1].get_feature_names_out(categorical_features)\n","\n","#combine all column names\n","all_columns= list(encoded_columns)+ list(df.columns.drop(categorical_features))\n","\n","#turn the array back to a dataframe\n","df_encoded= pd.DataFrame(df_encoded , columns= all_columns)\n","print(df_encoded.shape)\n","print(df_encoded.describe())\n","\n","#apply feature scaling\n","features_to_scale = ['Age', 'Fare']\n","sc= StandardScaler()\n","df_encoded[features_to_scale] = sc.fit_transform(df_encoded[features_to_scale])\n","df_encoded.to_csv('/content/drive/MyDrive/ML-AI projects/titanic survival prediction/Titanic_survival_prediction/competition/test_dataset_encoded_and_scaled.csv',index=False)\n","\n","#load the model\n","model_path='/content/drive/MyDrive/ML-AI projects/titanic survival prediction/Titanic_survival_prediction/training/best_lgb_model.pkl'\n","model = joblib.load(model_path)\n","\n","#get predictions\n","predictions = model.predict(df_encoded)\n","print(\"the predictions made by the model are \",predictions)\n","\n","#make a csv comprising of passenger id and prediction\n","results_df = pd.DataFrame({'PassengerId': passId, 'Survived': predictions})\n","results_df.to_csv('/content/drive/MyDrive/ML-AI projects/titanic survival prediction/Titanic_survival_prediction/competition/predictions.csv', index=False)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qWgbWPAe-4O-","executionInfo":{"status":"ok","timestamp":1739027915903,"user_tz":-60,"elapsed":3331,"user":{"displayName":"malama chali","userId":"16385961368052158169"}},"outputId":"21a2dcb3-3a68-4b62-e862-5a3c0ae3c2a3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["           Pclass         Age       SibSp       Parch        Fare\n","count  418.000000  332.000000  418.000000  418.000000  417.000000\n","mean     2.265550   30.272590    0.447368    0.392344   35.627188\n","std      0.841838   14.181209    0.896760    0.981429   55.907576\n","min      1.000000    0.170000    0.000000    0.000000    0.000000\n","25%      1.000000   21.000000    0.000000    0.000000    7.895800\n","50%      3.000000   27.000000    0.000000    0.000000   14.454200\n","75%      3.000000   39.000000    1.000000    0.000000   31.500000\n","max      3.000000   76.000000    8.000000    9.000000  512.329200\n","the number of missing values per feature is \n"," Pclass       0\n","Sex          0\n","Age         86\n","SibSp        0\n","Parch        0\n","Fare         1\n","Embarked     0\n","dtype: int64\n","the number of missing values per feature after imputation is \n"," Pclass      0\n","Sex         0\n","Age         0\n","SibSp       0\n","Parch       0\n","Fare        0\n","Embarked    0\n","dtype: int64\n","the categorical features are  ['Sex', 'Embarked']\n","(418, 10)\n","       Sex_female    Sex_male  Embarked_C  Embarked_Q  Embarked_S      Pclass  \\\n","count  418.000000  418.000000  418.000000  418.000000  418.000000  418.000000   \n","mean     0.363636    0.636364    0.244019    0.110048    0.645933    2.265550   \n","std      0.481622    0.481622    0.430019    0.313324    0.478803    0.841838   \n","min      0.000000    0.000000    0.000000    0.000000    0.000000    1.000000   \n","25%      0.000000    0.000000    0.000000    0.000000    0.000000    1.000000   \n","50%      0.000000    1.000000    0.000000    0.000000    1.000000    3.000000   \n","75%      1.000000    1.000000    0.000000    0.000000    1.000000    3.000000   \n","max      1.000000    1.000000    1.000000    1.000000    1.000000    3.000000   \n","\n","              Age       SibSp       Parch        Fare  \n","count  418.000000  418.000000  418.000000  418.000000  \n","mean    30.272590    0.447368    0.392344   35.627188  \n","std     12.634534    0.896760    0.981429   55.840500  \n","min      0.170000    0.000000    0.000000    0.000000  \n","25%     23.000000    0.000000    0.000000    7.895800  \n","50%     30.272590    0.000000    0.000000   14.454200  \n","75%     35.750000    1.000000    0.000000   31.500000  \n","max     76.000000    8.000000    9.000000  512.329200  \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["the predictions made by the model are  [0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 0 1 0 1\n"," 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0\n"," 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n"," 1 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n"," 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1\n"," 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n"," 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1\n"," 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n"," 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n"," 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0\n"," 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n"," 0 1 1 1 1 1 0 1 0 0 0]\n"]}]}]}