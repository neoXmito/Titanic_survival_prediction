{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","mount_file_id":"1JUL6BokgVD4TPLWPCuuPq7Q01pDqJcfI","authorship_tag":"ABX9TyPDgG3B6XF9WoEAhImX76Qp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["#**Importing the necessary libraries**"],"metadata":{"id":"C-hiJIpKbSNH"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier , AdaBoostClassifier\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn.utils import shuffle\n","!pip install xgboost\n","!pip install lightgbm\n","import xgboost as xgb\n","import lightgbm as  lgb\n","from sklearn.neural_network import MLPClassifier"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u6McLoKlbY-2","executionInfo":{"status":"ok","timestamp":1738983418529,"user_tz":-60,"elapsed":18517,"user":{"displayName":"malama chali","userId":"16385961368052158169"}},"outputId":"0d3c47c2-4fea-4571-82c4-78b1dc95b4e2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting xgboost\n","  Downloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n","Collecting nvidia-nccl-cu12 (from xgboost)\n","  Downloading nvidia_nccl_cu12-2.25.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n","Downloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl (223.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.25.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n","Successfully installed nvidia-nccl-cu12-2.25.1 xgboost-2.1.4\n","Collecting lightgbm\n","  Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.13.1)\n","Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lightgbm\n","Successfully installed lightgbm-4.5.0\n"]}]},{"cell_type":"markdown","source":["#**Loading the preprocessed data**"],"metadata":{"id":"eliNeTHvbgLu"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"QmPLrlKuZ0lX","executionInfo":{"status":"ok","timestamp":1738983426740,"user_tz":-60,"elapsed":1713,"user":{"displayName":"malama chali","userId":"16385961368052158169"}}},"outputs":[],"source":["X_train_path='/content/drive/MyDrive/ML-AI projects/titanic survival prediction/Titanic_survival_prediction/preprocessing/X_train.csv'\n","y_train_path='/content/drive/MyDrive/ML-AI projects/titanic survival prediction/Titanic_survival_prediction/preprocessing/y_train.csv'\n","X_test_path='/content/drive/MyDrive/ML-AI projects/titanic survival prediction/Titanic_survival_prediction/preprocessing/X_test.csv'\n","y_test_path='/content/drive/MyDrive/ML-AI projects/titanic survival prediction/Titanic_survival_prediction/preprocessing/y_test.csv'\n","\n","X_train =pd.read_csv(X_train_path)\n","y_train =pd.read_csv(y_train_path)\n","X_test =pd.read_csv(X_test_path)\n","y_test =pd.read_csv(y_test_path)\n"]},{"cell_type":"markdown","source":["#**Training of models**"],"metadata":{"id":"F0DcfM9FZ-WL"}},{"cell_type":"code","source":["models = {\n","    'Logistic Regression': LogisticRegression(),\n","    'Decision Tree': DecisionTreeClassifier(),\n","    'Random Forest': RandomForestClassifier(),\n","    'SVM': SVC(),\n","    'KNN': KNeighborsClassifier(),\n","    'Naive Bayes': GaussianNB(),\n","    'LightGBM': lgb.LGBMClassifier(),\n","    'XGBoost': xgb.XGBClassifier(),\n","    'AdaBoost': AdaBoostClassifier(),\n","    'Neural Network': MLPClassifier()\n","}\n","\n","\n","# Set the file path where you want to save the classification reports\n","filepath = '/content/drive/MyDrive/ML-AI projects/titanic survival prediction/Titanic_survival_prediction/training/classification_reports.txt'\n","\n","# Create or open the file in write mode\n","with open(filepath, 'w') as f:\n","    for model_name, model in models.items():\n","        print(f\"Training {model_name}...\")\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","\n","        # Print predictions to console\n","        print(f\"The predictions of the test set are: {y_pred}\")\n","\n","        # Generate classification report\n","        report = classification_report(y_test, y_pred)\n","\n","        # Print the classification report to console\n","        print(report)\n","\n","        # Write the model name and classification report to the text file\n","        f.write(f\"Classification Report for {model_name}:\\n\")\n","        f.write(report)\n","        f.write('-' * 80 + '\\n')\n","\n","print(f\"Classification reports saved to {filepath}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4n1k1kNtbrqm","executionInfo":{"status":"ok","timestamp":1738983687047,"user_tz":-60,"elapsed":13705,"user":{"displayName":"malama chali","userId":"16385961368052158169"}},"outputId":"f0543153-81c7-4aab-e808-16cd1d127f4f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Logistic Regression...\n","The predictions of the test set are: [0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0\n"," 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1\n"," 0 0 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n"," 0 1 0 1 0 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0\n"," 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1]\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.86      0.84       105\n","           1       0.79      0.74      0.76        74\n","\n","    accuracy                           0.81       179\n","   macro avg       0.81      0.80      0.80       179\n","weighted avg       0.81      0.81      0.81       179\n","\n","Training Decision Tree...\n","The predictions of the test set are: [0 1 0 1 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 1\n"," 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1\n"," 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1\n"," 0 1 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1\n"," 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1]\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.80      0.81       105\n","           1       0.73      0.76      0.74        74\n","\n","    accuracy                           0.78       179\n","   macro avg       0.78      0.78      0.78       179\n","weighted avg       0.78      0.78      0.78       179\n","\n","Training Random Forest...\n","The predictions of the test set are: [0 0 0 1 0 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0\n"," 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1\n"," 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1\n"," 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1\n"," 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1]\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.85      0.83       105\n","           1       0.77      0.72      0.74        74\n","\n","    accuracy                           0.79       179\n","   macro avg       0.79      0.78      0.78       179\n","weighted avg       0.79      0.79      0.79       179\n","\n","Training SVM...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return fit_method(estimator, *args, **kwargs)\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["The predictions of the test set are: [0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n"," 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1\n"," 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n"," 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0\n"," 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1]\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.88      0.85       105\n","           1       0.81      0.73      0.77        74\n","\n","    accuracy                           0.82       179\n","   macro avg       0.81      0.80      0.81       179\n","weighted avg       0.82      0.82      0.81       179\n","\n","Training KNN...\n","The predictions of the test set are: [0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n"," 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1\n"," 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1\n"," 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 1 0 0\n"," 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 1]\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.87      0.85       105\n","           1       0.80      0.74      0.77        74\n","\n","    accuracy                           0.82       179\n","   macro avg       0.81      0.80      0.81       179\n","weighted avg       0.81      0.82      0.81       179\n","\n","Training Naive Bayes...\n","The predictions of the test set are: [0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0\n"," 1 1 0 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1\n"," 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 1\n"," 0 1 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 0\n"," 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1]\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.77      0.80       105\n","           1       0.71      0.78      0.74        74\n","\n","    accuracy                           0.78       179\n","   macro avg       0.77      0.78      0.77       179\n","weighted avg       0.78      0.78      0.78       179\n","\n","Training LightGBM...\n","[LightGBM] [Info] Number of positive: 268, number of negative: 444\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000116 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 201\n","[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 10\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.376404 -> initscore=-0.504838\n","[LightGBM] [Info] Start training from score -0.504838\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","The predictions of the test set are: [0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0\n"," 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1\n"," 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n"," 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0\n"," 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 1 1]\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.84      0.85       105\n","           1       0.78      0.80      0.79        74\n","\n","    accuracy                           0.82       179\n","   macro avg       0.82      0.82      0.82       179\n","weighted avg       0.82      0.82      0.82       179\n","\n","Training XGBoost...\n","The predictions of the test set are: [0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0\n"," 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1\n"," 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n"," 0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0\n"," 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1]\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.86      0.84       105\n","           1       0.79      0.74      0.76        74\n","\n","    accuracy                           0.81       179\n","   macro avg       0.81      0.80      0.80       179\n","weighted avg       0.81      0.81      0.81       179\n","\n","Training AdaBoost...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["The predictions of the test set are: [0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n"," 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1\n"," 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n"," 0 1 0 0 0 0 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0\n"," 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1]\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.87      0.83       105\n","           1       0.79      0.70      0.74        74\n","\n","    accuracy                           0.80       179\n","   macro avg       0.80      0.78      0.79       179\n","weighted avg       0.80      0.80      0.80       179\n","\n","Training Neural Network...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["The predictions of the test set are: [0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n"," 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1\n"," 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n"," 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0\n"," 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1]\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.87      0.83       105\n","           1       0.79      0.70      0.74        74\n","\n","    accuracy                           0.80       179\n","   macro avg       0.80      0.78      0.79       179\n","weighted avg       0.80      0.80      0.80       179\n","\n","Classification reports saved to /content/drive/MyDrive/ML-AI projects/titanic survival prediction/Titanic_survival_prediction/training/classification_reports.txt\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["#**Saving the Best Model**"],"metadata":{"id":"EdC6KWBMjTUR"}},{"cell_type":"code","source":["import lightgbm as lgb\n","from sklearn.model_selection import GridSearchCV\n","\n","# Hyperparameters for tuning\n","param_grid = {\n","    'num_leaves': [31, 50, 100],\n","    'max_depth': [5, 10, 15],\n","    'learning_rate': [0.01, 0.05, 0.1],\n","    'n_estimators': [100, 200, 300]\n","}\n","\n","# Create the LightGBM model\n","lgb_model = lgb.LGBMClassifier()\n","\n","# Apply GridSearchCV to find the best hyperparameters\n","grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, cv=5, scoring='accuracy')\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best model\n","best_lgb_model = grid_search.best_estimator_\n","\n","# Print the best parameters\n","print(f\"Best Parameters: {grid_search.best_params_}\")\n","print(f\"Best Accuracy: {grid_search.best_score_}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1W7oEv_rXYkcAEb2mdyRirauSOiqjKY7r"},"id":"BWWJxiJsjsPj","executionInfo":{"status":"ok","timestamp":1738984726434,"user_tz":-60,"elapsed":67553,"user":{"displayName":"malama chali","userId":"16385961368052158169"}},"outputId":"4dcf4de3-2599-4cdd-cc13-42b4cafb9494"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["!pip install joblib\n","import joblib\n","\n","# Save the model\n","joblib.dump(best_lgb_model, '/content/drive/MyDrive/ML-AI projects/titanic survival prediction/Titanic_survival_prediction/training/best_lgb_model.pkl')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ymCsKYiFkXTa","executionInfo":{"status":"ok","timestamp":1738984863143,"user_tz":-60,"elapsed":1226,"user":{"displayName":"malama chali","userId":"16385961368052158169"}},"outputId":"e6926f5a-6bef-435e-ec51-bc7bf58cd458"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n"]},{"output_type":"execute_result","data":{"text/plain":["['/content/drive/MyDrive/ML-AI projects/titanic survival prediction/Titanic_survival_prediction/training/best_lgb_model.pkl']"]},"metadata":{},"execution_count":12}]}]}